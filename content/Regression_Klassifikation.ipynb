{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b9880fe",
   "metadata": {},
   "source": [
    "# Machine Learning Regression und Klassifikation Vertiefung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64193641",
   "metadata": {},
   "source": [
    "## TEIL A: Regression mit Hauspreisberechnung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65505f5c",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; border: 5px solid #a10000ff;\">\n",
    "\n",
    "**Hinweis:** In den Codezellen sind jeweils einige Codeteile nicht programmiert. Diesen Code müssen Sie ergänzen. Die jeweiligen Stellen sind mit einem Kommentar und dem Keyword **TODO** vermerkt und z.T. Stellen mit ... markiert.\n",
    "\n",
    "Ausserdem gibt es einige assert Statements. Diese geben einen Fehler aus, sollte etwas bei Ihrer Programmierung nicht korrekt sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9336170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e0ed32",
   "metadata": {},
   "source": [
    "In diesem Dataset wurden verschiedene Eigenschaften von Liegenschaften erfasst. \n",
    "\n",
    "Dabei soll nun von den Eigenschaften auf den Hauspreis geschlossen werden. Der Hauspreis ist somit die **Zielvariable** oder engl. *Target*, ähnlich dem Label in der Klassifikation.\n",
    "\n",
    "Die Berechnungen des Hauspreises, werden wir mit einem Regressionsmodell machen.\n",
    "\n",
    "Das Dataset das wir benutzten, ist das California Housing Dataset:\n",
    "https://media.geeksforgeeks.org/wp-content/uploads/20240522145850/housing%5B1%5D.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9797acc3",
   "metadata": {},
   "source": [
    "**Führen Sie die nächsten zwei Zellen aus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f7376",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if file housing.csv exists, if not download it\n",
    "if not os.path.exists(\"./data/housing.csv\"):\n",
    "    #load housing dataset from URL and save file locally\n",
    "    url = \"https://media.geeksforgeeks.org/wp-content/uploads/20240522145850/housing%5B1%5D.csv\"\n",
    "    response = requests.get(url)\n",
    "    with open(\"./data/housing.csv\", \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "# load csv into a pandas dataframe\n",
    "df_housing = pd.read_csv(\"./data/housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09b0b1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>-121.09</td>\n",
       "      <td>39.48</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1665.0</td>\n",
       "      <td>374.0</td>\n",
       "      <td>845.0</td>\n",
       "      <td>330.0</td>\n",
       "      <td>1.5603</td>\n",
       "      <td>78100.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>-121.21</td>\n",
       "      <td>39.49</td>\n",
       "      <td>18.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2.5568</td>\n",
       "      <td>77100.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>-121.22</td>\n",
       "      <td>39.43</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2254.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>92300.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>-121.32</td>\n",
       "      <td>39.43</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1860.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>741.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>1.8672</td>\n",
       "      <td>84700.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>-121.24</td>\n",
       "      <td>39.37</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2785.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>530.0</td>\n",
       "      <td>2.3886</td>\n",
       "      <td>89400.0</td>\n",
       "      <td>INLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0        -122.23     37.88                41.0        880.0           129.0   \n",
       "1        -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2        -122.24     37.85                52.0       1467.0           190.0   \n",
       "3        -122.25     37.85                52.0       1274.0           235.0   \n",
       "4        -122.25     37.85                52.0       1627.0           280.0   \n",
       "...          ...       ...                 ...          ...             ...   \n",
       "20635    -121.09     39.48                25.0       1665.0           374.0   \n",
       "20636    -121.21     39.49                18.0        697.0           150.0   \n",
       "20637    -121.22     39.43                17.0       2254.0           485.0   \n",
       "20638    -121.32     39.43                18.0       1860.0           409.0   \n",
       "20639    -121.24     39.37                16.0       2785.0           616.0   \n",
       "\n",
       "       population  households  median_income  median_house_value  \\\n",
       "0           322.0       126.0         8.3252            452600.0   \n",
       "1          2401.0      1138.0         8.3014            358500.0   \n",
       "2           496.0       177.0         7.2574            352100.0   \n",
       "3           558.0       219.0         5.6431            341300.0   \n",
       "4           565.0       259.0         3.8462            342200.0   \n",
       "...           ...         ...            ...                 ...   \n",
       "20635       845.0       330.0         1.5603             78100.0   \n",
       "20636       356.0       114.0         2.5568             77100.0   \n",
       "20637      1007.0       433.0         1.7000             92300.0   \n",
       "20638       741.0       349.0         1.8672             84700.0   \n",
       "20639      1387.0       530.0         2.3886             89400.0   \n",
       "\n",
       "      ocean_proximity  \n",
       "0            NEAR BAY  \n",
       "1            NEAR BAY  \n",
       "2            NEAR BAY  \n",
       "3            NEAR BAY  \n",
       "4            NEAR BAY  \n",
       "...               ...  \n",
       "20635          INLAND  \n",
       "20636          INLAND  \n",
       "20637          INLAND  \n",
       "20638          INLAND  \n",
       "20639          INLAND  \n",
       "\n",
       "[20640 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e65082",
   "metadata": {},
   "source": [
    "### Aufgabe 1\n",
    "\n",
    "Sie haben sich sicherlich die Features im Dataframe angeschaut. Machine Learning Modelle benötigen die Daten als Zahlen um diese im Features Space abbilden zu können. Jedoch haben wir mit ocean_proximity ein Feature das Kategorische Daten enthält.\n",
    "\n",
    "**Frage:** Um welche Art von Skalentyp handelt es sich? Wie übertragen wir ein solches Feature in einen Feature Space?\n",
    "\n",
    "<br>\n",
    "<details>\n",
    "<summary><b>Lösung: Klicke hier für die Lösung.</b></summary>\n",
    "\n",
    "Es handelt sich um eine Nominalskala. Die Ordnung ist nicht klar gegeben. Es ist z.B. nicht klar ob Island näher am Ozean ist wie Near Ocean zum Beispiel.\n",
    "\n",
    "Diese können wir mit dem sogenannten One-Hot-Encoding in einen mathematischen Raum übertragen. Dies geschieht indem wir für jede Kategorie eine neue Dimension anlegen und dort eine 1 vermerken wenn die Kategorie zutrifft und bei allen anderen eine 0. Wir nutzen dazu den One-Hot-Encoder von Scikit-learn.\n",
    "\n",
    "Zusätzlich entfernen wir noch alle Data Samples die leere Werte haben.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557f4b8b",
   "metadata": {},
   "source": [
    "Wir listen nun einmal alle Arten von Werten die ocean_proximity haben kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030101bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir verwenden OneHotEncoder aus sklearn.preprocessing\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# TODO Konfiguriere das One-Hot-Encoding auf der Spalte 'ocean_proximity' indem du das DataFrame df_housing mit der Spaltenangabe als Parameter einfügst. Beispiel: ohe.fit(df_iris[['petal length (cm)']])\n",
    "ohe.fit(...)\n",
    "\n",
    "# Wir erstellen ein neues DataFrame mit den kodierten Spalten und füge sie dem ursprünglichen DataFrame hinzu. Danach entfernen wir die ursprüngliche Spalte 'ocean_proximity'.\n",
    "df_housing_encoded = pd.concat([df_housing, pd.DataFrame(ohe.transform(df_housing[['ocean_proximity']]), columns=ohe.get_feature_names_out(['ocean_proximity']))], axis=1)\n",
    "df_housing_encoded.drop('ocean_proximity', axis=1, inplace=True)\n",
    "\n",
    "# Wir entfernen Zeilen mit fehlenden Werten, da diese nicht für das Training des Modells verwendet werden können\n",
    "df_housing_encoded.dropna(inplace=True)\n",
    "\n",
    "df_housing_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49801d8",
   "metadata": {},
   "source": [
    "### Aufgabe 2\n",
    "\n",
    "Wir möchten nun noch die Daten normalisieren. Dies hilft einigen Modellen zum Beispiel künstlichen Neuronalen Netzwerken schneller zu optimieren und zu lernen.\n",
    "\n",
    "Wir wenden die min-max-Skalierung an. Das heisst alle Features haben danach einen minimalen Wert von 0 und einen maximalen Wert von 1.\n",
    "\n",
    "Wie könnten Sie dies berrechnen? Vervollständige danach den Code unten.\n",
    "\n",
    "<details>\n",
    "<summary><b>Tipp 1:</b> Klicke hier für den ersten Tipp.</summary>\n",
    "\n",
    "Wie nutzen Sie das Minimum eines Features und das Maximum damit nachher alle Werte eines Features zwischen (inklusive) 0 und 1 sind?\n",
    "\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<details>\n",
    "<summary><b>Lösung:</b> Klicken Sie hier um die Formel anzuzeigen.</summary>\n",
    "\n",
    "$scaled\\_value = \\frac{value-min}{max - min}$\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Normalisieren der numerischen Features mit Min-Max-Skalierung\n",
    "\n",
    "# Wir haben nun eine Liste von numerischen Features\n",
    "numerical_features = df_housing_encoded.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# TODO Normalisiere die numerischen Features mit Min-Max-Skalierung\n",
    "for feature in numerical_features:\n",
    "    ...\n",
    "\n",
    "df_housing_encoded\n",
    "\n",
    "# Prüfen ob die numerischen Features korrekt normalisiert wurden\n",
    "assert (df_housing_encoded[numerical_features].min().min() >= 0) and (df_housing_encoded[numerical_features].max().max() <= 1), \"Die numerischen Features wurden nicht korrekt normalisiert.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a48e1e",
   "metadata": {},
   "source": [
    "### Aufgabe 3\n",
    "\n",
    "Unterteilen Sie das Dataset in ein Trainings und Testteil wie im vorherigen Abschnitt bereits gemacht.\n",
    "Nutzen Sie auch einen Train/Test Split von 80/20 und den Random State 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc6c3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir Unterteile das Dataset in Trainigns- und Testdaten. Die Spalte 'median_house_value' ist die Zielvariable, die wir vorhersagen möchten. \n",
    "# Deshalb wird sie von den Features getrennt. Wir entfernen die Zielvariable aus den Features bei der Parameterübergabe mit df_housing_encoded.drop('median_house_value', axis=1) und benutze sie als zweiten Parameter in der train_test_split Funktion.\n",
    "# TODO fülle die fehlenden Parameter in der train_test_split Funktion aus damit 20% der Daten als Testdaten verwendet werden.\n",
    "\n",
    "X_housing_train, X_housing_test, y_housing_train, y_housing_test = train_test_split(df_housing_encoded.drop('median_house_value', axis=1), df_housing_encoded['median_house_value'], test_size=..., random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe772d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO diese Tests laufen lassen, um zu prüfen ob die Aufteilung korrekt ist\n",
    "assert X_housing_train.shape[0] == 16346, f\"Erwartete Anzahl Trainingsdaten: 16346, aktuell sind es: {X_housing_train.shape[0]}\"\n",
    "assert X_housing_test.shape[0] == 4087 , f\"Erwartete Anzahl Testdaten: 4087, aktuell sind es: {X_housing_test.shape[0]}\"\n",
    "\n",
    "# Prüfe ob median_house_value aus den Features entfernt wurde\n",
    "assert 'median_house_value' not in X_housing_train.columns, \"median_house_value wurde nicht aus den Features entfernt.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0690ff11",
   "metadata": {},
   "source": [
    "### Aufgabe 4\n",
    "\n",
    "1. Nutzen Sie die MLPRegressor Klasse um ein Modell zu instantieren. Die Klasse wurde bereits am Anfang importiert. Sie können die gleichen Parameter verwenden wie in Aufgabe 7 beim MLPClassifier.\n",
    "2. Trainieren Sie nun das Modell mit dem Aufruf der fit(Trainingsdaten, Targets) Methode.\n",
    "\n",
    "Optional: Weitere Infos zur MLPRegressor Klasse: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45141773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir erstellen nun ein Regressionsmodell bestehend aus mehreren Perzeptronen (MLPRegressor)\n",
    "mlp_regressor = MLPRegressor(hidden_layer_sizes=(10,), max_iter=500, random_state=42)\n",
    "\n",
    "# TODO Trainieren Sie das Modell mit den Trainignsdaten als erstes Argument und den zugehörigen Labels als zweites Argument. Tipp: benutzen Sie die X_housing_train und y_housing_train Variablen.\n",
    "mlp_regressor.fit(..., ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05781762",
   "metadata": {},
   "source": [
    "### Aufgabe 5\n",
    "\n",
    "Evaluieren Sie nun ihr Modell mit den Testdaten. Dieses Mal können wir aber nicht die Accuracy nutzen, da diese nur für Klassifikationen geeignet ist.\n",
    "Wir nutzen stattdessen den Root-Mean-Squared-Error. Dieser wird wie folgt berechnet:\n",
    "\n",
    "- $y$: Echtes Label\n",
    "- $\\hat{y}$: Voraussage des Modells\n",
    "\n",
    "$\\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2}$\n",
    "\n",
    "In Prosa geschieht hier folgendes:\n",
    "Für jedes Data Samples im Testdatenset wird das echte Label minus der Voraussage gerechnet. Dieses Ergebnis wird quadriert. Danach wird die Summe über alle diese quadrierten \"Fehler\" berechnet und geteilt durch die Anzahl Samples gerechnet. Somit der Mittelwert des quadrierten Fehlers. Zuletzt ziehen wir noch die Wurzel damit das Ergebnis besser interpretierbar wird, bezüglich der Grössenordnung.\n",
    "\n",
    "Vervollständigen Sie den Code um den MSE zu berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55863e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir berechnen nun mit dem Modell die Vorhersagen für die Testdaten als einzigen Parameter in der predict-Methode\n",
    "y_housing_pred = mlp_regressor.predict(X_housing_test)\n",
    "\n",
    "# Wir berechnen den Root Mean Squared Error (RMSE) auf dem Testset\n",
    "mse_test = np.sqrt(np.sum((y_housing_pred - y_housing_test)**2) / len(y_housing_test))\n",
    "print(f'Mean Squared Error on Test Set: {mse_test:.4f}')\n",
    "\n",
    "assert abs(mse_test - 0.0197) < 0.01, \"Der Mean Squared Error auf dem Testset ist nicht korrekt berechnet.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6102df",
   "metadata": {},
   "source": [
    "### Aufgabe 6\n",
    "Führen Sie die Code-Zelle unten aus. Dabei wird für ein Datasample aus dem Test Dataset der Hauspreis berechnet.\n",
    "\n",
    "Was fällt Ihnen bei dieser Vorhersage auf?\n",
    "\n",
    "\n",
    "\n",
    "Weshalb ist die Vorhersage in dieser Grössenordnung und wie könnten Sie dieses Problem lösen?\n",
    "\n",
    "<br>\n",
    "<details>\n",
    "<summary><b>Lösung: Klicke hier für die Lösung</b>.</summary>\n",
    "\n",
    "Wir haben auch den House Value mit Min Max Normalisierung skaliert. Wie könnte man dies nun zu einem korrekten Hauswert zurückrechnen?\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1488a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel Vorhersage des Preises für ein einzelnes Haus aus dem Testset\n",
    "\n",
    "y_housing_pred_single = mlp_regressor.predict(X_housing_test[:1])\n",
    "print(f'Der berechnete Hauswert beträgt: {y_housing_pred_single[0]:.2f}')\n",
    "\n",
    "# TODO: Optionale Zusatzaufgabe: Skalieren Sie die Vorhersage zurück in den Originalmassstab. Sie können auf die Originalen min und max Werte der Spalte 'median_house_value' im ursprünglichen DataFrame df_housing zugreifen.\n",
    "#y_pred_scaled = ...\n",
    "#print(f'Der berechnete Hauswert im Originalmaßstab beträgt: {y_pred_scaled[0]:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54679056",
   "metadata": {},
   "source": [
    "### Aufgabe 7\n",
    "\n",
    "Wir zeigen nun in einem Scatter Plot noch einige zufällige Datenpunkte an, wobei wir vergleichen möchten was der echte Hauspreis ist und was unser Modell berechnet hat.\n",
    "Lassen Sie die nächste Code Zelle laufen und beantworten Sie die folgende Frage.\n",
    "\n",
    "**Frage**\n",
    "Woran erkennt man einen kleinen Fehler des Modells und wie einen grossen?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab4bc3f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_housing_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plotte die Vorhersagen des Modells gegen die tatsächlichen Werte nutze aber nur 50 zufällige Datenpunkte und zeichne den Fehler als Linie ein\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m random_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(\u001b[43my_housing_test\u001b[49m), size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m y_housing_pred_sampled \u001b[38;5;241m=\u001b[39m y_housing_pred[random_indices]\n\u001b[0;32m      5\u001b[0m y_housing_test_sampled \u001b[38;5;241m=\u001b[39m y_housing_test\u001b[38;5;241m.\u001b[39miloc[random_indices]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_housing_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Plotte die Vorhersagen des Modells gegen die tatsächlichen Werte nutze aber nur 50 zufällige Datenpunkte und zeichne den Fehler als Linie ein\n",
    "\n",
    "random_indices = np.random.choice(len(y_housing_test), size=50, replace=False)\n",
    "y_housing_pred_sampled = y_housing_pred[random_indices]\n",
    "y_housing_test_sampled = y_housing_test.iloc[random_indices]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.scatter(range(len(y_housing_pred_sampled)), y_housing_pred_sampled, color='red', label='Berechnete Werte')\n",
    "plt.scatter(range(len(y_housing_test_sampled)), y_housing_test_sampled, color='blue', label='Tatsächliche Werte')\n",
    "for i in range(len(y_housing_pred_sampled)):\n",
    "    plt.plot([i, i], [y_housing_pred_sampled[i], y_housing_test_sampled.iloc[i]], color='gray', linestyle='--', linewidth=0.5)\n",
    "plt.xlabel('Testdaten Index')\n",
    "plt.ylabel('Median Hauswert (normalisiert)')\n",
    "plt.title('Vorhersagen vs Tatsächliche Werte des Hauswerts')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9126ef",
   "metadata": {},
   "source": [
    "### Zusatzaufgabe: Teste das Training ohne min-max Normalisierung\n",
    "\n",
    "Führe nochmals einen Traingslauf durch ohne, dass die min-max Skalierung genutzt wurde.\n",
    "Beobachte wie lange das Training nun läuft. \n",
    "\n",
    "**Frage**: Was ist schneller? Min-Max normalisierte Daten oder die ursprünglichen Daten?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eaa366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0a10b4c",
   "metadata": {},
   "source": [
    "## Kontrollfragen: Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9718682d",
   "metadata": {},
   "source": [
    "**Kontrollfrage 3**\n",
    "\n",
    "Was ist der Output einer Regression und wie verhält sich dieser im Vergleich zu der Klassifikation?\n",
    "\n",
    "\n",
    "\n",
    "**Kontrollfrage 4**\n",
    "\n",
    "Welchen Vorteil hat die Normalisierung der numerischen Features gebracht? Wie lautete die Formel?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73722808",
   "metadata": {},
   "source": [
    "## Zusatzaufgabe TEIL B: Klassifikation von Iris Blumen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b22c9",
   "metadata": {},
   "source": [
    "In dieser Aufgabe sehen wir uns das Iris Dataset an. Hierbei geht es darum die Blumen anhand ihrer Blütenblätter- (Petal) und Kelchblättermasse (Sepal) zu klassifizieren.\n",
    "\n",
    "Wir importieren zuerst einmal einige Libraries die wir nutzen möchten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef4cceb",
   "metadata": {},
   "source": [
    "<div style=\"padding: 5px; border: 5px solid #a10000ff;\">\n",
    "\n",
    "**Hinweis:** In den Codezellen sind jeweils einige Codeteile nicht programmiert. Diesen Code müssen Sie ergänzen. Die jeweiligen Stellen sind mit einem Kommentar und dem Keyword **TODO** vermerkt und z.T. Stellen mit ... markiert.\n",
    "\n",
    "Ausserdem gibt es einige assert Statements. Diese geben einen Fehler aus, sollte etwas bei Ihrer Programmierung nicht korrekt sein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734d087d",
   "metadata": {},
   "source": [
    "Nun laden wir das Iris Dataset, welches bereits in der Library angeboten wird. Wir speichern es auch in einem DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a7b9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load iris dataset\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#create pandas dataframe from iris\n",
    "df_iris = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df_iris['target'] = iris.target\n",
    "df_iris['target_names'] = df_iris['target'].apply(lambda x: iris.target_names[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd009e4",
   "metadata": {},
   "source": [
    "Eine Aufgabe, die von Machine Learning übernommen wird, ist die Klassifizierung. \n",
    "\n",
    "Dabei ist es die Aufgabe ein **Data Sample** (z.B. eine Katze oder einen Hund) aufgrund von bestimmten **Features** (z.B. Anzahl Streifen, Grösse) einer bestimmten Kategorie auch **Klasse** genannt zuzuweisen. Die einzelnen Data Samples sind jeweils mit einem **Label** gekennzeichnet, zu welcher Klasse sie gehören."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761d8acf",
   "metadata": {},
   "source": [
    "### Aufgabe 8\n",
    "Zeigen Sie nun das Pandas Dataframe mit den Daten an.\n",
    "\n",
    "**Fragen**\n",
    "\n",
    "Was sind die Features die wir in diesem Beispiel nutzen?\n",
    "\n",
    "\n",
    "Was beinhaltet die Spalte target bzw. target_names?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8406671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Zeige hier das Pandas DataFrame an\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16ef30a",
   "metadata": {},
   "source": [
    "### Aufgabe 9\n",
    "Wir zeigen nun die paarweise Kombination von den Features an. Führen Sie dazu die nächste Code-Zelle aus.\n",
    "\n",
    "**Frage**\n",
    "\n",
    "Wenn Sie die Blumen von Auge anhand eines der Diagramme unterscheiden müssten.\n",
    "Welche Feature Kombination würde sich gut eignen? Begründen Sie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1728b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the feature spaces with two features each\n",
    "pairplt = sns.pairplot(df_iris.drop('target', axis=1), hue='target_names', height=2, palette='tab10')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff3350c",
   "metadata": {},
   "source": [
    "### Aufgabe 10\n",
    "In diesem Fall möchten wir nun die Blumen in die Klassen setosa (0), versicolor (1) und verginica (2) einteilen. Die Daten haben alle bereits die sogenannten **Labels** zugewiesen. Diese werden manchmal auch target genannt und sind in den Daten in den Spalten target und target_names vorhanden.\n",
    "\n",
    "Wenn wir ein oder mehrere Features in einem mathematischen Raum kombinieren, entsteht ein sogennanter **Feature Space** (Merkmalsraum).\n",
    "Ein solcher Feature Space für die *petal width* und *petal length* sieht wie folgt aus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4129342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Vervollständigen Sie die Spaltennamen der Parameter x und y für einen Scatterplot der Petal Length gegen die Petal Width\n",
    "\n",
    "sns.scatterplot(x='...', y='...',\n",
    "                hue='target_names', data=df_iris.drop('target', axis=1), palette='tab10')\n",
    "\n",
    "# Placing Legend outside the Figure\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60405aaa",
   "metadata": {},
   "source": [
    "\n",
    "**Fragen**\n",
    "\n",
    "Wie viele Dimensionen hat der Feature Space im obigen Beispiel?\n",
    "\n",
    "\n",
    "Wie viele Dimensionen können wir in einem Feature Space haben?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83762628",
   "metadata": {},
   "source": [
    "### Aufgabe 11\n",
    "\n",
    "Ein Machine Learning Model versucht eine oder mehrere **Decision Boundaries** also Entscheidungsgrenzen in den Feature Space zu platzieren, so dass möglichst viele Data Samples korrekt klassifiziert werden.\n",
    "\n",
    "**Frage**\n",
    "\n",
    "Beschreiben Sie wie Sie zwei linearen Decision Boundaries im Feature Space oben platzieren würden um die drei Klassen auseinanderzuhalten.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6905907d",
   "metadata": {},
   "source": [
    "### Aufgabe 12\n",
    "\n",
    "Machine Learning Modelle treffen Entscheidungen anhand von Daten, welche Sie zu Beginn der «Kalibrierung» genutzt haben, um zu lernen. Man nennt diese Daten **Trainingsdaten**, da das Modell sozusagen damit trainiert wird. Wenn nun ein Machine Learning Modell getestet wird (heisst: wie gut funktioniert das Modell?), werden ihm neue Daten sogenannte **Testdaten** präsentiert, welche nicht für das Training genutzt wurden. \n",
    "\n",
    "**Fragen**\n",
    "\n",
    "Was ist der Vorteil bei diesem Vorgehen? \n",
    "\n",
    "\n",
    "Was könnte ein Nachteil sein?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe25c47",
   "metadata": {},
   "source": [
    "### Aufgabe 13\n",
    "\n",
    "Damit wir Trainings- und Testdaten haben, teilen wir die Daten in Trainings und Testdaten ein. Das gleiche passiert auch mit den targets. Wir nutzen eine fertige Funktion von sklearn dafür.\n",
    "\n",
    "Vielfach werden die Features in einer Variable X gespeichert und die Labels bzw. Targets in einer Variable y.\n",
    "\n",
    "Wir machen das gleich und kennzeichnen gleich im Variablennamen auch ob die Daten die Trainings oder Testdaten sind.\n",
    "\n",
    "**Fragen**\n",
    "\n",
    "In welchem Verhältnis werden die Daten mit dem Befehl train_test_split unten aufgeteilt?\n",
    "\n",
    "\n",
    "Wie viele Data Samples sind nun im Trainings Dataset und wie viele im Testdataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de847c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_iris_train, X_iris_test, y_iris_train, y_iris_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "#TODO Ausgabe der Anzahl der Trainings- und Testdaten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a0241",
   "metadata": {},
   "source": [
    "### Aufgabe 14\n",
    "\n",
    "Wir trainieren nun unseren ersten Classifier und testen diesen auch. \n",
    "\n",
    "Vorerst nutzen wir einen fixfertigen Classifier von Sklearn den wir instanziieren müssen und dann \"fitten\". Hinter der fit Funktion versteckt sich ein Trainingsprozess in dem das Modell von den Trainingsdaten lernt.\n",
    "Vervollständige die Befehle anhand der Kommentare.\n",
    "\n",
    "**Bemerkung:** Das Modell wurde extra so konfiguriert, dass nicht eine 100% Genauigkeit resultiert, damit wir die Genauigkeit auswerten können. Deshalb erscheint auch eine **ConvergenceWarning**, diese können Sie **ignorieren**.\n",
    "\n",
    "Wir evaluieren das Modell mittels der Accuracy. Diese wird berechnet indem die Anzahl korrekt klassifizierten Data Samples geteilt durch die Anzahl aller Data Samples gerechnet wird:\n",
    "\n",
    "  $ Accuracy = \\frac{\\text{Anzahl korrekt Klassifizierte Data Samples}}{\\text{Alle Data Samples}} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9194b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10,), max_iter=500, random_state=42)\n",
    "\n",
    "#TODO Trainiere das Modell mit den Trainingsdaten als erstes Argument und den zugehörigen Labels als zweites Argument\n",
    "mlp.fit(..., ...)\n",
    "\n",
    "#TODO Berechne nun mit dem Modell die Klassen für die Testdaten als einzigen Parameter in der predict-Methode\n",
    "y_iris_pred = mlp.predict(...)\n",
    "\n",
    "# TODO Berechne die Genauigkeit des Modells\n",
    "# Dies können wir berechnen indem wir zählen, wie viele der vorhergesagten Labels mit den tatsächlichen Labels übereinstimmen und dies durch die Gesamtanzahl der Testdaten teilen\n",
    "accuracy = ...\n",
    "\n",
    "# Test ob die Accuracy korrekt berechnet wurde\n",
    "assert (abs(accuracy-0.93) < 0.01), \"Die Genauigkeit des Modells ist nicht korrekt berechnet.\"\n",
    "print(f'Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9171e4",
   "metadata": {},
   "source": [
    "### Aufgabe 8\n",
    "\n",
    "Wir schauen uns nun noch genauer an, welche Klassen am meisten verwechselt wurden. Dazu werden wir eine Konfusionsmatrix nutzen. Dabei werden die tatsächlichen Labels den vorhergesagten Labels gegenübergestellt und aufgezeichnet, wie oft jede Kombination vorkommt.\n",
    "\n",
    "\n",
    "**Frage**\n",
    "Betrachten Sie nun nochmals die paarweisen Feature Spaces aus Aufgabe 2 betrachten.\n",
    "Welche zwei Klassen werden wohl am meisten verwechselt?\n",
    "\n",
    "\n",
    "Lassen Sie nun die Zelle unten laufen und interpretieren Sie die Konfusionsmatrix. Stimmte ihre Vermutung?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc1a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir zeigen nun eine Konfusionsmatrix an, um die Leistung des Modells zu visualisieren. \n",
    "\n",
    "conf_matrix = ConfusionMatrixDisplay.from_predictions(y_iris_test, y_iris_pred, display_labels=iris.target_names)\n",
    "conf_matrix.ax_.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ac9a04",
   "metadata": {},
   "source": [
    "## Kontrollfragen Klassifikation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4147ef13",
   "metadata": {},
   "source": [
    "**Kontrollfrage 1**\n",
    "\n",
    "Ein Machine-Learning Modell klassifiziert die Schüler*innen ob sie mit dem Velo, den ÖV oder zu Fuss zur Schule kommen. \n",
    "In den Daten wird pro Schüler*in und Tag erfasst, wie weit der Schulweg ist, wie lange die Reisedauer war, ob der/die Schüler*in ein Velo besitzt und wie weit die nächste ÖV-Haltestelle vom Wohnort entfernt ist.\n",
    "\n",
    "Was sind in diesem Beispiel\n",
    "\n",
    "    - Features?\n",
    "    - Klassen?\n",
    "    - Data Samples?\n",
    "    \n",
    "Was wäre ein Beispiel für eine Ein und Ausgabe des Modells?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Kontrollfrage 2**\n",
    "\n",
    "Beschreiben Sie das Vorgehen, um ein Klassifikationsmodell zu evaluieren und dabei die Accuracy zu berechnen.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
